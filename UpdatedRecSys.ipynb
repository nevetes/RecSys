{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "import xlrd\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from pyxlsb import open_workbook as open_xlsb\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import implicit\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>ga:totalEvents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35ee4ff41378badb08aac8e56cf7759fea6f3c5b42898...</td>\n",
       "      <td>9461581</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ff5015618651a16649d9340032018a9f4ee292cfc57e...</td>\n",
       "      <td>9525153</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fcb1358a130f6a37b43f7da166c8065f7ad450385b6...</td>\n",
       "      <td>8109942</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ffb2cc7df4dc609f2106e55c943c44b359401fbb04d3f...</td>\n",
       "      <td>9231251</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3919087a2b968b0e5064c0eceab17ca1d2bf80aaa9d16...</td>\n",
       "      <td>9491140</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             user_id  cluster_id  \\\n",
       "0   35ee4ff41378badb08aac8e56cf7759fea6f3c5b42898...     9461581   \n",
       "1   8ff5015618651a16649d9340032018a9f4ee292cfc57e...     9525153   \n",
       "2   02fcb1358a130f6a37b43f7da166c8065f7ad450385b6...     8109942   \n",
       "3   ffb2cc7df4dc609f2106e55c943c44b359401fbb04d3f...     9231251   \n",
       "4   3919087a2b968b0e5064c0eceab17ca1d2bf80aaa9d16...     9491140   \n",
       "\n",
       "   ga:totalEvents  \n",
       "0              85  \n",
       "1              78  \n",
       "2              68  \n",
       "3              68  \n",
       "4              65  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we import the data cluster_lookup is a lookup table of hotels. Cleaned_df is the updated Dataframe with views info\n",
    "cluster_lookup = pickle.load(open('cluster_lookup_upto21Feb.pickle', 'rb'))\n",
    "cleaned_df = pickle.load(open('df_upto21Feb.pickle', 'rb'))\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now create the sparse ratings matrix of users and hotels:\n",
    "customers = list(np.sort(cleaned_df.user_id.unique())) # Get our unique customers\n",
    "products = list(cleaned_df.cluster_id.unique()) # Get our unique hotels that were booked\n",
    "quantity = list(cleaned_df['ga:totalEvents']) # All of our room bookings\n",
    "cat_type1 = CategoricalDtype(categories = customers)\n",
    "cat_type2 = CategoricalDtype(categories = products)\n",
    "rows = cleaned_df.user_id.astype(cat_type1).cat.codes \n",
    "cols = cleaned_df.cluster_id.astype(cat_type2).cat.codes \n",
    "\n",
    "bookings_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity= 99.99828106048203\n"
     ]
    }
   ],
   "source": [
    "#In terms of sparsity this means\n",
    "matrix_size = bookings_sparse.shape[0]*bookings_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_bookings = len(bookings_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_bookings/matrix_size))\n",
    "print('sparsity=',sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.1):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered  \n",
    "#This will return our training set, a test set that has been binarized to 0/1 for booked/not booked, \n",
    "#and a list of which users that have at least one item masked. We will test the performance of the recommender system \n",
    "#on these users only. pct_test = 0.1 means I am masking 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total users= 391786\n",
      "Users with items masked= 128238\n"
     ]
    }
   ],
   "source": [
    "# We create an array of costumers and hotels like we made earlier\n",
    "customers_arr = np.array(customers) # Array of customer IDs from the ratings matrix\n",
    "products_arr = np.array(products) # Array of product IDs from the ratings matrix\n",
    "product_train, product_test, product_users_altered = make_train(bookings_sparse, pct_test = 0.2)\n",
    "print('total users=', len(customers))\n",
    "print('Users with items masked=', len(product_users_altered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 240.0/240 [01:45<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "#model for final recommendations\n",
    "alpha = 800\n",
    "new_model = implicit.als.AlternatingLeastSquares(factors=40, iterations=240, regularization = 0.1)\n",
    "trans_ptrain=product_train.T\n",
    "train=new_model.fit((trans_ptrain*alpha).astype('double'))\n",
    "new_uservecs=new_model.user_factors\n",
    "new_itemvecs=new_model.item_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to recommend hotels\n",
    "def rec_hotels(cluster_id, mf_train, user_vecs, item_vecs, customer_list, item_list, cluster_lookup, num_items = 10):\n",
    "\t'''\n",
    "\tThis function will return the top recommended items to our users \n",
    "\t\n",
    "\tparameters:\n",
    "\t\n",
    "\tcluster_id - hotel id number that you want to get recommendations for\n",
    "\t\n",
    "\tmf_train - The training matrix you used for matrix factorization fitting\n",
    "\t\n",
    "\tuser_vecs - the user vectors from your fitted matrix factorization\n",
    "\t\n",
    "\titem_vecs - the item vectors from your fitted matrix factorization\n",
    "\t\n",
    "\tcustomer_list - an array of the customer's ID numbers that make up the rows of your ratings matrix \n",
    "\t\t\t\t\t(in order of matrix)\n",
    "\t\n",
    "\titem_list - an array of the products that make up the columns of your ratings matrix\n",
    "\t\t\t\t\t(in order of matrix)\n",
    "\t\n",
    "\titem_lookup - A simple pandas dataframe of the unique product ID/product descriptions available\n",
    "\t\n",
    "\tnum_items - The number of items you want to recommend in order of best recommendations. Default is 10. \n",
    "\t\n",
    "\treturns:\n",
    "\t\n",
    "\t- The top n recommendations chosen based on the user/item vectors for items never interacted with\n",
    "\t'''\n",
    "\t\n",
    "\tcluster_ind = np.where(item_list == cluster_id)[0][0] # Returns the index row of our customer id\n",
    "\trecommend_vector=new_model.similar_items(cluster_ind, N=num_items)\n",
    "    #filtered_recommend_vector=filrecvec.append(recommend_vector()\n",
    "#\tprint(recommend_vector)\n",
    "\tproduct_idx = [x[0] for x in recommend_vector]# Sort the indices of the items into order \n",
    "#\tprint(\"product_idx\")   \n",
    "#\tprint(product_idx) \n",
    "\t# of best recommendations\n",
    "\trec_list = [] # start empty list to store items\n",
    "\tfor index in product_idx:\n",
    "\t\tcode=item_list[index]\n",
    "#\t\tprint(\"index,code\")\n",
    "#\t\tprint(index,code)\n",
    "\t\trec_list.append([code, cluster_lookup['hotel_name'].loc[cluster_lookup.cluster_id==code].iloc[0],\n",
    "                         cluster_lookup['city_id'].loc[cluster_lookup.cluster_id==code].iloc[0]])\n",
    "\tcodes=[item[0] for item in rec_list]\n",
    "\tdescriptions=[item[1] for item in rec_list]\n",
    "\tcities=[item[2] for item in rec_list]\n",
    "\tfinal_frame = pd.DataFrame({'ClusterID': codes, 'Hotelname': descriptions, 'Hotelcity':cities}) # Create a dataframe \n",
    "\tfinal_frame[['ClusterID', 'Hotelname', 'Hotelcity']]\n",
    "\t#my_city=(final_frame['Hotelcity']==city_id)\n",
    "\t#return final_frame[my_city]\n",
    "\treturn final_frame[['ClusterID', 'Hotelname', 'Hotelcity']] # Switch order of columns around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Novotel Muenchen cCity Arnulfpark:\n",
      "   ClusterID                               Hotelname  Hotelcity\n",
      "0    9526409        Novotel Muenchen City Arnulfpark    37463.0\n",
      "1    9530059               BEST WESTERN Atrium Hotel    37463.0\n",
      "2    8851448           B%26B%20Affittacamere%20Larix        1.0\n",
      "3    7068516           ibis Muenchen City Arnulfpark    37463.0\n",
      "4    7104200                       Germania MÃ¼nchen    37463.0\n",
      "5    9533861  Mercure Hotel Muenchen Neuperlach Sued    37463.0\n",
      "6    4055500          ibis Styles MÃ¼nchen Ost-Messe    37463.0\n",
      "7    9657709    Holiday Inn Express Munich City West    37463.0\n",
      "8    9144045                           Bristol Hotel   208561.0\n",
      "9    9530088                     ErzgieÃerei Europe    37463.0\n"
     ]
    }
   ],
   "source": [
    "#example of recommendations:\n",
    "print('Recommendations for Novotel Muenchen cCity Arnulfpark:')\n",
    "print(rec_hotels(9526409, product_train, new_uservecs, new_itemvecs, customers_arr, products_arr, cluster_lookup,num_items=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving recommendations to a file\n",
    "import csv\n",
    "\n",
    "outfile=open('recommendationslist_upto21Feb.tsv','w')\n",
    "writer=csv.writer(outfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "for cluster_id in products_arr:\n",
    "    cluster_ind=np.where(products_arr==cluster_id)[0][0]\n",
    "\n",
    "    recommend_vector=new_model.similar_items(cluster_ind, N=500)\n",
    "    product_idx = [x[0] for x in recommend_vector]# Sort the indices of the items into order \n",
    "    print(product_idx)\n",
    "    rec_list = [] # start empty list to store items\n",
    "    for i,index in enumerate(product_idx):\n",
    "        code=products_arr[index]\n",
    "        print(i,index,code)\n",
    "        rec_list.append([i,cluster_id,code])\n",
    "        writer.writerow([i,cluster_id, code])\n",
    "outfile.close()\n",
    "   #print(rec_list)\n",
    "print('your file with recommendations is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
